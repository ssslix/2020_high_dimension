library(MASS)
fix(Boston)
lm.fit <- lm(medv~., data = Boston)
summary(lm.fit)
library(glmnet)
install.packages('glmnet')
library(glmnet)
x <- model.matrix(medv~.,Boston)[,-1]
y <- Boston$medv
View(x)
install.packages(c("lars", "msgps"))
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
library(MASS)
dim(Boston)
n,p <- dim(X)
n,p <- dim(X)[1],dim(X)[2]
n <- dim(X)[0]
n <- dim(X)[0];p <- dim(X)[1]
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
dim(X)
dim(y)
X <- model.matrix(medv~.,Boston)[,-1]
y <- Boston$medv
dim(y)
y <- Boston$medv
y
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
n
n <- dim(X)[1];p <- dim(X)[2]
y1 = rep(0,n)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
##R自带函数结果
beta_hat_1
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/lasso1.R', encoding = 'UTF-8', echo=TRUE)
lasso.mod=glmnet(t(X), y, alpha=1,lambda=0.01)
summary(lasso.mod)
lasso.coef = predict(lasso.mod,type = "coefficients",s= 0.01)
lasso.coef
beta_hat_1
lasso.mod=glmnet(t(X), y, alpha=1,lambda=0.01,offset = 0)
summary(lasso.mod)
lasso.coef = predict(lasso.mod,type = "coefficients",s= 0.01)
lasso.coef
lar1 <- lars(t(X),y,type = "lasso")
beta_hat_2 <- lar1$beta
beta_hat_1
beta_hat_2
lar1$Cp[which.min(lar$Cp)]
1
summary(lar1)
lar1$Cp
which.min(lar1$Cp)
beta_hat_2[13,]
beta_hat_1
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/ridge1.R', echo=TRUE)
X <- t(X)
coef=solve(X%*%t(X)+alpha*diag(p))%*%X%*%y
coef
library(MASS)
lr <- lm.ridge(y~X,data=Boston,lambda = 0.01,model=TRUE)
lr <- lm.ridge(y~.,data=Boston,lambda = 0.01,model=TRUE)
lr
X <- cbind(X,rep(1,n))
X <- cbind(rep(1,n),X)
rep(1,n)
X <- model.matrix(medv~.,Boston)[,-1]
y <- Boston$medv
n <- dim(X)[1];p <- dim(X)[2]
alpha=0.01
X <- cbind(rep(1,n),X)
X <- t(X)
coef=solve(X%*%t(X)+alpha*diag(p))%*%X%*%y
coef
X
View(X)
coef=solve(X%*%t(X)+alpha*diag(p))%*%X%*%y
coef=solve(X%*%t(X)+alpha*diag(p+1))%*%X%*%y
coef
lr <- lm.ridge(y~t(X),data=Boston,lambda = 0.01,model=TRUE)
lr <- lm.ridge(y~t(X),lambda = 0.01,model=TRUE)
lr <- lm.ridge(y~.,lambda = 0.01,model=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/ridge1.R', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/ridge1.R', echo=TRUE)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/ridge1.R', echo=TRUE)
head(Boston)
library(xtable)
xtable(head(Boston))
lm.fit <- lm(medv~., data = Boston)
summary(lm.fit)
xtable(summary(lm.fit))
View(lasso.coef)
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/ridge1.R', echo=TRUE)
lr$coef
library(xtable)
xtable(coef)
xtable(t(coef))
xtable(lr$coef)
lr$coef
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/ridge1.R', echo=TRUE)
library(MASS)
library(glmnet)
x <- model.matrix(medv~.,Boston)[,-1]
y <- Boston$medv
grid=10^seq(1,-3 ,length=lO0)
grid=10^seq(1,-3 ,length=1O0)
grid=10^seq(1,-3 ,length=100)
ridge.mod <- glmnet(x,y,alpha=0,lambda = grid)
dim(ridge.mod)
View(ridge.mod)
dim(coef(ridge.mod))
plot(ridge.mod)
ridge.mod <- cv.glmnet(x,y,alpha=0,lambda = grid)
plot(ridge.mod)
dim(coef(ridge.mod))
help("cv.glmnet")
opt_lambda <- ridge.mod$lambda.minopt_lambda
opt_lambda <- ridge.mod$grid.minopt_lambda
opt_lambda <- ridge.mod$lambda
opt_lambda
opt_lambda <- ridge.mod$lambda.minopt_lambda
opt_lambda
opt_lambda <- ridge.mod$lambda.min
opt_lambda2 <- cv_fit$lambda.lse
cv_fit <- cv.glmnet(x,y,alpha=0,lambda = grid)
plot(cv_fit)
opt_lambda1 <- cv_fit$lambda.min
opt_lambda2 <- cv_fit$lambda.lse
grid=10^seq(1,-3 ,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
coef(ridge.mod)[,100]
coef(ridge.mod)[,1]
plot(ridge.mod)
set.seed(512)
cv.out=cv.glmnet(x,y,alpha=0)#交叉验证
plot(cv.out)
bestlam1=cv.out$lambda.min
bestlam2=cv.out$lambda.1se
ridge.pred=predict(ridge.mod,s=c(bestlam1,bestlam2),newx=x)
mean((ridge.pred[,1]-y)^2)#当lambda=lambda.min
mean((ridge.pred[,2]-y)^2)#当lambda=lambda.lse
predict(ridge.mod,s=c(bestlam1,bestlam2),newx=x,type="coefficients")
source('E:/Github/2020_high_dimension/统计学习方法/大报告/code/Ridge.R', encoding = 'UTF-8', echo=TRUE)
a<-predict(ridge.mod,s=c(bestlam1,bestlam2),newx=x,type="coefficients")
t(a)
xtable(a)
library(MASS)
library(glmnet)
x <- model.matrix(medv~.,Boston)[,-1]
y <- Boston$medv
grid=10^seq(1,-3 ,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
coef(ridge.mod)[,100]
coef(ridge.mod)[,1]
plot(ridge.mod)
library(MASS)
library(glmnet)
x <- model.matrix(medv~.,Boston)[,-1]
y <- Boston$medv
grid=10^seq(-3,10 ,length=100)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
coef(ridge.mod)[,100]
coef(ridge.mod)[,1]
plot(ridge.mod)
source('G:/GitHub/2020_high_dimension/统计学习方法/大报告/code/LR.r', echo=TRUE)
source('G:/GitHub/2020_high_dimension/统计学习方法/大报告/code/LR.r', echo=TRUE)
4.745^2
