\documentclass[cn]{elegantpaper}
\author{邵李翔\quad 赵张弛 \quad 祖劭康}
\title{线性回归,岭回归以及Lasso回归}
\date{}
\usepackage{float}
\begin{document}
    
\maketitle
\begin{abstract}
  我们采用Boston数据集，使用线性回归、lasso、岭回归三种方式进行建模，以数据集中的medv变量为响应变量，其余13个变量为预测变量，探究之间的线性关系。并比较三种模型求解出来的系数，分析三种方法的优缺点。
\end{abstract}
\section{数据集描述}
本次实验采用的数据集为Boston (波士顿房价)数据集，它记录了波士顿周围 506 个街区的 medv
(房价中位数)。我们将设法用 13 个预测变量如 rm (每栋住宅的平均房间数)， age (平均房
龄)， lstat (社会经济地位低的家庭所占比例)等来预测 medv (房价中位数)。下表是部分数据集展示。
\begin{table}[ht]
    \centering
    \caption{数据集中部分数据展示}
    \begin{tabular}{rrrrrrrrrrrrrrr}
      \hline
     & crim & zn & indus & chas & nox & rm & age & dis & rad & tax & ptratio & black & lstat & medv \\ 
      \hline
    1 & 0.01 & 18.00 & 2.31 & 0.00 & 0.54 & 6.58 & 65.20 & 4.09 & 1.00 & 296.00 & 15.30 & 396.90 & 4.98 & 24.00 \\ 
      2 & 0.03 & 0.00 & 7.07 & 0.00 & 0.47 & 6.42 & 78.90 & 4.97 & 2.00 & 242.00 & 17.80 & 396.90 & 9.14 & 21.60 \\ 
      3 & 0.03 & 0.00 & 7.07 & 0.00 & 0.47 & 7.18 & 61.10 & 4.97 & 2.00 & 242.00 & 17.80 & 392.83 & 4.03 & 34.70 \\ 
       \hline
    \end{tabular}
\end{table}

\section{线性回归}
由于最小二乘法求解线性模型参数能直接得到解析解，所以我们对所有预测变量进行多元回归,得到的结果如表2。由各个预测变量对应的系数的值可以看出来，有些变量比如black，age等系数绝对值小于0.01，可以说与响应变量——房价中位数关系不大，而且表格第五列是系数显著性检验的结果，比如indus、age对应的p值显然是表明接受原假设，认为该变量的系数应该等于0。说明线性回归在某些数据集上还存在一定的局限性。
\begin{table}[H]
    \centering
    \caption{多元线性回归拟合结果}
    \begin{tabular}{rrrrr}
      \hline
     & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
      \hline
    (Intercept) & 36.4595 & 5.1035 & 7.14 & 0.0000 \\ 
      crim & -0.1080 & 0.0329 & -3.29 & 0.0011 \\ 
      zn & 0.0464 & 0.0137 & 3.38 & 0.0008 \\ 
      indus & 0.0206 & 0.0615 & 0.33 & 0.7383 \\ 
      chas & 2.6867 & 0.8616 & 3.12 & 0.0019 \\ 
      nox & -17.7666 & 3.8197 & -4.65 & 0.0000 \\ 
      rm & 3.8099 & 0.4179 & 9.12 & 0.0000 \\ 
      age & 0.0007 & 0.0132 & 0.05 & 0.9582 \\ 
      dis & -1.4756 & 0.1995 & -7.40 & 0.0000 \\ 
      rad & 0.3060 & 0.0663 & 4.61 & 0.0000 \\ 
      tax & -0.0123 & 0.0038 & -3.28 & 0.0011 \\ 
      ptratio & -0.9527 & 0.1308 & -7.28 & 0.0000 \\ 
      black & 0.0093 & 0.0027 & 3.47 & 0.0006 \\ 
      lstat & -0.5248 & 0.0507 & -10.35 & 0.0000 \\ 
       \hline
    \end{tabular}
\end{table}

\input{lasso.tex}
\input{ridge.tex}

\section{总结}
对于Boston数据集直接采用线性回归进行参数估计效果并不好，我们分别采用lasso回归与岭回归方法同样对该数据集进行参数估计，lasso具有变量选择的效果，而且基于最小角回归算法得到的lasso估计参数比我们自己采用循环坐标下降法计算得到的参数效果好。而岭回归具有压缩系数的作用，但无法将系数压缩到0。




\end{document}

